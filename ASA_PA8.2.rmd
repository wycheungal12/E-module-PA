---
title: "SOA Predictive Analytics Exam, Module 8, Section 2"
---
If you are using R 3.6.0 or later, the following command will ensure that the random number generator being used is the same as in prior versions of R. Because these modules were developed using R 3.5.0, output that depends on random numbers used the older generator. Running this code will have your output match that shown in the modules.


```{r}
# Run this chunk if using R 3.6.0 or later.
RNGkind(sample.kind = "Rounding")
```

If you are using R 4.0.0 or later, the following command will ensure that read.csv() interprets variables whose values are characters as factor variables. This was the default behavior in prior versions of R. All code is written assuming such variables are factor variables.

```{r}
# Run this chunk if using R 4.0.0 or later. You may get what looks like an error message. It can be ignored.
options(stringsAsFactors = TRUE)
```

Run CHUNK 1 to simulate some two-dimensional data.

```{r echo = FALSE}
# CHUNK 1
library(ggplot2)
library(gridExtra)
set.seed(1000)
income_male <- rnorm(100, 70000, 10000)
income_female <- rnorm(100, 45000, 5000)
age <- rnorm(100, 65, 10)
age2 <- rnorm(100, 35, 5)

df.raw <- data.frame(a = c(income_male, income_female), b = c(age, age2))

ggplot(data = df.raw, aes(x = b, y = a)) +
  geom_point() +
  theme(axis.text = element_blank()) +
  ggtitle("Raw data")
```

Run CHUNK 2 to assign the points to groups at random.

```{r echo = FALSE}
# CHUNK 2
df.raw$group_random <- as.factor(sample(c(1, 2), size = 100, replace = TRUE))
ggplot(data = df.raw, aes(x = b, y = a, col = group_random)) +
  geom_point() +
  theme(axis.text = element_blank(), legend.title = element_blank()) +
  ggtitle("Random Grouping")
df.raw$group_random <- NULL
```

Run CHUNK 3 to perform K-means clustering with two groups. Note that the data have been scaled, an important step when using this algorithm.

```{r echo = FALSE}
# CHUNK 3
df <- df.raw
df$a <- scale(df$a)
df$b <- scale(df$b)
km2 <- kmeans(df, 2)
df$group2 <- as.factor(km2$cluster)

ggplot(data = df, aes(x = b, y = a, col = group2)) +
  geom_point() +
  theme(axis.text = element_blank(), legend.title = element_blank()) +
  ggtitle("Clustering with 2 groups")
```

Run CHUNK 4 to add the centers to the plot.

```{r echo = FALSE}
# CHUNK 4
df <- df.raw
df$a <- scale(df$a)
df$b <- scale(df$b)
km2 <- kmeans(df, 2)
df$group2 <- as.factor(km2$cluster)

ggplot(data = df, aes(x = b, y = a, col = group2)) +
  geom_point() +
  annotate("point", x = km2$centers[1, 2], y = km2$centers[1, 1], size = 3, color = "black") +
  annotate("text", x = km2$centers[1, 2] + 0.5, y = km2$centers[1, 1], label = paste("(", round(km2$centers[1, 2], 2), ",", round(km2$centers[1, 1], 2), ")", sep = ""), color = "black") +
  annotate("point", x = km2$centers[2, 2], y = km2$centers[2, 1], size = 3, color = "black") +
  annotate("text", x = km2$centers[2, 2] + 0.5, y = km2$centers[2, 1], label = paste("(", round(km2$centers[2, 2], 2), ",", round(km2$centers[2, 1], 2), ")", sep = ""), color = "black") +
  ggtitle("Clustering with 2 groups") +
  theme(legend.title = element_blank())
```

Run CHUNK 5 to set a seed for the kmeans function and to determine a solution. iter.max = 1 means only one iteration is conducted. Hence here we see the two randomly selected centers. The "Lloyd" algorithm is the one described in this course - begin with random centers and then assign the points to clusters based on which center is closest.

Play with CHUNK 5 by changing max.iter from 1 to 2 to 3, etc. to see how the algorithm moves toward a solution. Then, using max.iter = 100, change the seed to see if different clusters result. Because this dataset is well behaved, you may not see a difference. Note that the graphs show the centers of the current clusters, and so with max.iter = 1 you see the initial clusters, but not the initial centers. 

```{r echo = FALSE}
# CHUNK 5

df <- df.raw
set.seed(200)
df$a <- scale(df$a)
df$b <- scale(df$b)
km2 <- kmeans(df, 2, iter.max = 1, algorithm = "Lloyd")
df$group2 <- as.factor(km2$cluster)

centers1 <- km2$centers
km2$tot.withinss

ggplot(data = df, aes(x = b, y = a, col = group2)) +
  geom_point() +
  annotate("point", x = centers1[1, 2], y = centers1[1, 1], size = 3, color = "black") +
  annotate("text", x = centers1[1, 2] + 0.5, y = centers1[1, 1], label = paste("(", round(km2$centers[1, 2], 2), ",", round(centers1[1, 1], 2), ")", sep = ""), color = "black") +
  annotate("point", x = centers1[2, 2], y = centers1[2, 1], size = 3, color = "black") +
  annotate("text", x = centers1[2, 2] + 0.5, y = centers1[2, 1], label = paste("(", round(centers1[2, 2], 2), ",", round(centers1[2, 1], 2), ")", sep = ""), color = "black") +
  ggtitle("Clustering with 2 groups") +
  theme(legend.title = element_blank())
```

Run CHUNK 6 to do the clustering without standardization.

```{r}
# CHUNK 6
df <- df.raw

km2 <- kmeans(df, 2) # K-means algorithm - the default method is Hamilton-Wong
df$group2 <- as.factor(km2$cluster)

ggplot(data = df, aes(x = a, y = b, col = group2)) +
  geom_point() +
  ggtitle("Clustering without standardization") +
  theme(legend.title = element_blank())
```

Run CHUNK 7 to try out the elbow method.

```{r echo = FALSE}
# CHUNK 7

df <- df.raw

set.seed(200)
df$a <- scale(df$a)
df$b <- scale(df$b)


km1 <- kmeans(df, 1)
df$group <- as.factor(km1$cluster)
p1 <- ggplot(data = df, aes(x = b, y = a, col = group)) +
  geom_point() +
  ggtitle("k=1")

km2 <- kmeans(df, 2)
df$group <- as.factor(km2$cluster)
p2 <- ggplot(data = df, aes(x = b, y = a, col = group)) +
  geom_point() +
  ggtitle("k=2")

km3 <- kmeans(df, 3)
df$group <- as.factor(km3$cluster)
p3 <- ggplot(data = df, aes(x = b, y = a, col = group)) +
  geom_point() +
  ggtitle("k=3")

km4 <- kmeans(df, 4)
df$group <- as.factor(km4$cluster)
p4 <- ggplot(data = df, aes(x = b, y = a, col = group)) +
  geom_point() +
  ggtitle("k=4")

km5 <- kmeans(df, 5)
df$group <- as.factor(km5$cluster)
p5 <- ggplot(data = df, aes(x = b, y = a, col = group)) +
  geom_point() +
  ggtitle("k=5")

km6 <- kmeans(df, 6)
df$group <- as.factor(km6$cluster)
p6 <- ggplot(data = df, aes(x = b, y = a, col = group)) +
  geom_point() +
  ggtitle("k=6")

var.exp <- data.frame(
  k = c(1:6),
  bss_tss = c(
    km1$betweenss / km1$totss,
    km2$betweenss / km2$totss,
    km3$betweenss / km3$totss,
    km4$betweenss / km4$totss,
    km5$betweenss / km5$totss,
    km6$betweenss / km6$totss
  )
)

ggplot(data = var.exp, aes(x = k, y = bss_tss)) +
  geom_point() +
  geom_line() +
  annotate("path",
    x = 2 + 0.1 * cos(seq(0, 2 * pi, length.out = 100)),
    y = 0.76 + 0.05 * sin(seq(0, 2 * pi, length.out = 100)), color = "red"
  ) +
  ggtitle("Elbow plot")

library(gridExtra)
grid.arrange(p1, p2, ncol = 2)
grid.arrange(p3, p4, ncol = 2)
grid.arrange(p5, p6, ncol = 2)
```

Run CHUNKs 8-10 to perform agglomerative hierarchical clustering.

```{r echo = FALSE}
# CHUNK 8
## Set up the data again for use in the hierarchical clustering
set.seed(1000)
income_male <- rnorm(100, 70000, 10000)
income_female <- rnorm(100, 45000, 5000)
age <- rnorm(100, 65, 10)
age2 <- rnorm(100, 35, 5)

df <- data.frame(a = c(income_male, income_female), b = c(age, age2))

df$a <- scale(df$a)
df$b <- scale(df$b)
```

```{r}
# CHUNK 9
# Calculate the dissimilarity structure for our dataset
d_struct <- dist(df)

# Cluster the dissimilarity structure of our data
hc <- hclust(d_struct)
```


```{r}
# CHUNK 10
# Plot the dendrogram of our hierarchical cluster
plot(hc)

# Simple function to create a plot given a dataframe, hclust, and number of clusters
plot_cluster_slice <- function(df, hc, numclusters) {
  df$clusters <- as.factor(cutree(hc, numclusters))
  ggplot(data = df, aes(x = b, y = a, col = clusters)) +
    geom_point() +
    theme(axis.text = element_blank())
}

plot_cluster_slice(df, hc, 2)
plot_cluster_slice(df, hc, 3)
plot_cluster_slice(df, hc, 10)
```
